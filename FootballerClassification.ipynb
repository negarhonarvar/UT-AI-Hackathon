{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZXAdCteWgraH6oR78DJxW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/negarhonarvar/UT-AI-Hackathon/blob/main/FootballerClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Footballer Classification\n",
        "\n",
        "In this task, we classify footballer robots into 4 different categories:\n",
        "\n",
        "*   Defender\n",
        "*   Forward\n",
        "*   Goalkeeper\n",
        "*   Midfielder\n",
        "\n"
      ],
      "metadata": {
        "id": "ptCWSdhpF342"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "1FRivujpGQKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OWpYrslFzYB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Mounting"
      ],
      "metadata": {
        "id": "WdBFTU-JHJ0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "TRAIN_DIR = \"/content/drive/MyDrive/HeatMap_Data/train\"\n",
        "TEST_DIR = \"/content/drive/MyDrive/HeatMap_Data/test\"\n",
        "SUBMISSION_FILE = \"/content/drive/MyDrive/HeatMap_Data/submission.csv\""
      ],
      "metadata": {
        "id": "vtL8v-WEHJXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00415a8-bbe0-40d7-e9a3-6adbc1a30562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Set Up"
      ],
      "metadata": {
        "id": "MTLMgGt9HbNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 4\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "VAL_SPLIT = 0.1\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "i0M2F5-sHX_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "iP0DfAs_RKZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(15),\n",
        "    T.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=10),\n",
        "    T.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "DyMiRasZROzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loaders"
      ],
      "metadata": {
        "id": "lVGoHQiCHlYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_val_loaders():\n",
        "    dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR, transform=train_transforms)\n",
        "    num_data = len(dataset)\n",
        "    val_size = int(VAL_SPLIT * num_data)\n",
        "    train_size = num_data - val_size\n",
        "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "    val_ds.dataset.transform = val_transforms\n",
        "\n",
        "    targets = [dataset.targets[i] for i in train_ds.indices]\n",
        "    class_counts = np.bincount(targets)\n",
        "    class_weights = 1. / class_counts\n",
        "    sample_weights = [class_weights[t] for t in targets]\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(train_ds), replacement=True)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "    return train_loader, val_loader, dataset"
      ],
      "metadata": {
        "id": "5HulfM54Ho8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "7oOdGIGcHqQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes=NUM_CLASSES):\n",
        "    model = torchvision.models.resnet50(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Z7A5Xk1sHyYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "Sm3KD3lqHzP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs, lr):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
        "    model.to(DEVICE)\n",
        "    best_acc = 0.0\n",
        "    best_model_wts = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0\n",
        "        correct_samples = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_samples += (preds == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / total_samples\n",
        "        train_acc = correct_samples / total_samples\n",
        "\n",
        "        val_loss, val_acc = validate_model(model, val_loader, criterion)\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}: Train loss {train_loss:.4f}, Train acc {train_acc*100:.2f}%, Val loss {val_loss:.4f}, Val acc {val_acc*100:.2f}%\")\n",
        "\n",
        "    if best_model_wts is not None:\n",
        "        model.load_state_dict({k: v.to(DEVICE) for k, v in best_model_wts.items()})\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ayULFuvrIUZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test_images(model, dataset):\n",
        "    model.eval()\n",
        "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
        "    test_files = sorted(os.listdir(TEST_DIR), key=lambda x: int(os.path.splitext(x)[0]))\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for file in test_files:\n",
        "            path = os.path.join(TEST_DIR, file)\n",
        "            pil_img = Image.open(path).convert(\"RGB\")\n",
        "            tensor_img = val_transforms(pil_img).unsqueeze(0).to(DEVICE)\n",
        "            outputs = model(tensor_img)\n",
        "            _, predicted_idx = torch.max(outputs, 1)\n",
        "            predicted_class = idx_to_class[predicted_idx.item()]\n",
        "            predictions.append(predicted_class)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "-yvZi2pRIa3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Generation"
      ],
      "metadata": {
        "id": "jkxrQ3GrIsnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_submission(predictions):\n",
        "    with open(SUBMISSION_FILE, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Position\"])\n",
        "        for pred in predictions:\n",
        "            writer.writerow([pred])"
      ],
      "metadata": {
        "id": "jfzqwMvEIlJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "tnHPmlFjIvR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_loader, val_loader, dataset = get_train_val_loaders()\n",
        "    print(f\"Training samples: {len(train_loader.dataset)}, Validation samples: {len(val_loader.dataset)}\")\n",
        "    model = create_model(num_classes=NUM_CLASSES)\n",
        "    model = train_model(model, train_loader, val_loader, NUM_EPOCHS, LEARNING_RATE)\n",
        "    predictions = predict_test_images(model, dataset)\n",
        "    write_submission(predictions)\n",
        "    print(f\"Submission saved to {SUBMISSION_FILE}\")"
      ],
      "metadata": {
        "id": "oIAkJKDqIrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "8EFCJk-bI0RZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a097828-4e5f-42dc-a479-8f93cdd2e372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 358, Validation samples: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 190MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30: Train loss 0.4263, Train acc 89.66%, Val loss 0.1121, Val acc 97.44%\n",
            "Epoch 2/30: Train loss 0.1282, Train acc 95.25%, Val loss 0.0416, Val acc 100.00%\n",
            "Epoch 3/30: Train loss 0.1050, Train acc 96.37%, Val loss 0.1128, Val acc 97.44%\n",
            "Epoch 4/30: Train loss 0.0862, Train acc 97.49%, Val loss 0.0495, Val acc 97.44%\n",
            "Epoch 5/30: Train loss 0.0494, Train acc 98.32%, Val loss 0.0287, Val acc 100.00%\n",
            "Epoch 6/30: Train loss 0.0182, Train acc 99.72%, Val loss 0.0899, Val acc 94.87%\n",
            "Epoch 7/30: Train loss 0.0083, Train acc 99.72%, Val loss 0.0306, Val acc 100.00%\n",
            "Epoch 8/30: Train loss 0.0070, Train acc 100.00%, Val loss 0.0192, Val acc 100.00%\n",
            "Epoch 9/30: Train loss 0.0074, Train acc 99.72%, Val loss 0.0136, Val acc 100.00%\n",
            "Epoch 10/30: Train loss 0.0042, Train acc 100.00%, Val loss 0.0145, Val acc 100.00%\n",
            "Epoch 11/30: Train loss 0.0022, Train acc 100.00%, Val loss 0.0226, Val acc 100.00%\n",
            "Epoch 12/30: Train loss 0.0117, Train acc 99.44%, Val loss 0.0244, Val acc 100.00%\n",
            "Epoch 13/30: Train loss 0.0068, Train acc 100.00%, Val loss 0.0119, Val acc 100.00%\n",
            "Epoch 14/30: Train loss 0.0056, Train acc 100.00%, Val loss 0.0086, Val acc 100.00%\n",
            "Epoch 15/30: Train loss 0.0040, Train acc 100.00%, Val loss 0.0161, Val acc 100.00%\n",
            "Epoch 16/30: Train loss 0.0036, Train acc 100.00%, Val loss 0.0135, Val acc 100.00%\n",
            "Epoch 17/30: Train loss 0.0045, Train acc 100.00%, Val loss 0.0273, Val acc 97.44%\n",
            "Epoch 18/30: Train loss 0.0028, Train acc 100.00%, Val loss 0.0133, Val acc 100.00%\n",
            "Epoch 19/30: Train loss 0.0129, Train acc 99.72%, Val loss 0.0216, Val acc 97.44%\n",
            "Epoch 20/30: Train loss 0.0029, Train acc 100.00%, Val loss 0.0133, Val acc 100.00%\n",
            "Epoch 21/30: Train loss 0.0019, Train acc 100.00%, Val loss 0.0158, Val acc 100.00%\n",
            "Epoch 22/30: Train loss 0.0104, Train acc 99.72%, Val loss 0.0133, Val acc 100.00%\n",
            "Epoch 23/30: Train loss 0.0094, Train acc 99.72%, Val loss 0.0521, Val acc 97.44%\n",
            "Epoch 24/30: Train loss 0.0020, Train acc 100.00%, Val loss 0.0193, Val acc 100.00%\n",
            "Epoch 25/30: Train loss 0.0051, Train acc 100.00%, Val loss 0.0169, Val acc 100.00%\n",
            "Epoch 26/30: Train loss 0.0022, Train acc 100.00%, Val loss 0.0228, Val acc 97.44%\n",
            "Epoch 27/30: Train loss 0.0047, Train acc 99.72%, Val loss 0.0176, Val acc 100.00%\n",
            "Epoch 28/30: Train loss 0.0075, Train acc 100.00%, Val loss 0.0156, Val acc 100.00%\n",
            "Epoch 29/30: Train loss 0.0025, Train acc 100.00%, Val loss 0.0210, Val acc 100.00%\n",
            "Epoch 30/30: Train loss 0.0025, Train acc 100.00%, Val loss 0.0174, Val acc 100.00%\n",
            "Submission saved to /content/drive/MyDrive/HeatMap_Data/submission.csv\n"
          ]
        }
      ]
    }
  ]
}